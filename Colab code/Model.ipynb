{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UqKxU7f3mfz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfcPkGCe2dbe",
        "outputId": "8d2e089c-381c-4d9c-df6c-270733b6e413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.9.24)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Ni-Mraa42sGx",
        "outputId": "b9451143-b873-480c-f264-38f6b01ad973"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b467f62-afd6-4ef4-a310-bee7efac2c16\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b467f62-afd6-4ef4-a310-bee7efac2c16\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 70 bytes\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnPUogSMpD58",
        "outputId": "0c648ceb-d3e3-4706-955d-b2131f2f2e98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cardiomegaly-disease-prediction-using-cnn.zip to /content\n",
            " 92% 57.0M/61.7M [00:00<00:00, 97.8MB/s]\n",
            "100% 61.7M/61.7M [00:00<00:00, 98.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d rahimanshu/cardiomegaly-disease-prediction-using-cnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7KpePOs2xEW",
        "outputId": "239c6d8c-ee7a-40fd-9bf9-c14d4755b499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "# install splitfolders to split dataset\n",
        "! pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iatr9YTC21Dq"
      },
      "outputs": [],
      "source": [
        "# import all libraries needed\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import zipfile\n",
        "import splitfolders\n",
        "import cv2\n",
        "import shutil\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, Dense, Flatten, MaxPooling2D, AveragePooling2D, Conv2D\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnYTXO2W23rr"
      },
      "outputs": [],
      "source": [
        "loc_zip = 'cardiomegaly-disease-prediction-using-cnn.zip'\n",
        "zip_ref = zipfile.ZipFile(loc_zip, 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIQJZLPtpQJK"
      },
      "outputs": [],
      "source": [
        "# Make image directory path\n",
        "\n",
        "train_dir = '/content/train/train'\n",
        "val_dir = '/content/test/test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/img'\n",
        "!mkdir '/content/img/true'\n",
        "!mkdir '/content/img/false'"
      ],
      "metadata": {
        "id": "W9vg1FgmsHTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move of true\n",
        "\n",
        "t_train = os.path.join(train_dir, 'true')\n",
        "t_val = os.path.join(val_dir, 'true')\n",
        "\n",
        "t_list = [t_train, t_val]\n",
        "destination = '/content/img/true'\n",
        "\n",
        "\n",
        "for source in t_list:\n",
        "  allfiles = os.listdir(source)\n",
        "  # print(allfiles)\n",
        "  for f in allfiles:\n",
        "      shutil.move(source +'/' + f, destination +'/' + f)\n",
        "\n"
      ],
      "metadata": {
        "id": "2lfVP5SEqOuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move of false\n",
        "\n",
        "t_train = os.path.join(train_dir, 'false')\n",
        "t_val = os.path.join(val_dir, 'false')\n",
        "\n",
        "t_list = [t_train, t_val]\n",
        "destination = '/content/img/false'\n",
        "\n",
        "\n",
        "for source in t_list:\n",
        "  allfiles = os.listdir(source)\n",
        "  # print(allfiles)\n",
        "  for f in allfiles:\n",
        "      shutil.move(source +'/' + f, destination +'/' + f)\n",
        "\n"
      ],
      "metadata": {
        "id": "QSyf-VI9sl9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir '/content/img/split'\n",
        "\n",
        "data_dir = '/content/img'\n",
        "output = '/content/img/split'\n",
        "\n",
        "splitfolders.ratio(data_dir, output=output, seed=1337, ratio=(.7,0.1,0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52MhP0m7szKS",
        "outputId": "12257ef1-5186-49c8-c9fc-424deae69539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 4438 files [00:00, 4653.15 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseDir= '/content/img/split'\n",
        "trainDir = os.path.join(baseDir, 'train')\n",
        "valDir = os.path.join(baseDir,'val')\n",
        "testDir = os.path.join(baseDir,'test')"
      ],
      "metadata": {
        "id": "jKAB936JtLqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVBQjvfjsNcY"
      },
      "outputs": [],
      "source": [
        "# Gather train data\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for r,d,f in os.walk(trainDir):\n",
        "  for file in f:\n",
        "    if \".png\" in file:\n",
        "      image_path = os.path.join(r,file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.resize(image, (128,128))\n",
        "      x_train.append(image)\n",
        "      label = image_path.split(os.path.sep)[-2]\n",
        "      y_train.append(label)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yeh_AGuSshJM"
      },
      "outputs": [],
      "source": [
        "# Gather validation data\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "for r,d,f in os.walk(valDir):\n",
        "  for file in f:\n",
        "    if \".png\" in file:\n",
        "      image_path = os.path.join(r,file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.resize(image, (128,128))\n",
        "      x_val.append(image)\n",
        "      label = image_path.split(os.path.sep)[-2]\n",
        "      y_val.append(label)\n",
        "\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather validation data\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for r,d,f in os.walk(testDir):\n",
        "  for file in f:\n",
        "    if \".png\" in file:\n",
        "      image_path = os.path.join(r,file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.resize(image, (128,128))\n",
        "      x_test.append(image)\n",
        "      label = image_path.split(os.path.sep)[-2]\n",
        "      y_test.append(label)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "iLUxK7eitmF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0PBNe6AsiiS",
        "outputId": "e736d51f-e8d7-455c-c06a-40ca9354d555"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data= (3106, 128, 128, 3)\n",
            "Train Label= (3106,)\n",
            "Validation Data= (442, 128, 128, 3)\n",
            "Validation Label= (442,)\n",
            "Test Data= (890, 128, 128, 3)\n",
            "Test Label= (890,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Data=\", x_train.shape)\n",
        "print(\"Train Label=\", y_train.shape)\n",
        "print(\"Validation Data=\", x_val.shape)\n",
        "print(\"Validation Label=\", y_val.shape)\n",
        "print(\"Test Data=\", x_test.shape)\n",
        "print(\"Test Label=\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoder implementation in each train & test label\n",
        "lb = LabelEncoder()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_val = lb.fit_transform(y_val)\n",
        "y_test = lb.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "a_S0BXo0pLxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "f = 0\n",
        "\n",
        "for i in y_train:\n",
        "  if i == 0:\n",
        "    f+=1\n",
        "  else :\n",
        "    t+=1\n",
        "\n",
        "print('True = ', t)\n",
        "print('False = ', f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQhcfU4VQHNJ",
        "outputId": "035bd7cc-98e4-491b-bc24-1b5a1336cd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True =  1553\n",
            "False =  1553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dikarenakan Dataset sudah balance maka tidak perlu dilakukan downsampli/oversampling"
      ],
      "metadata": {
        "id": "yt_q7AmxQmUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_iterator = train_datagen.flow([x_train,x_train], y_train, batch_size=64)"
      ],
      "metadata": {
        "id": "NgsB__84uM2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = ImageDataGenerator(width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "val_iterator = val_datagen.flow([x_val,x_val], y_val, batch_size=64)\n"
      ],
      "metadata": {
        "id": "npcyr-Fmuc61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "test_iterator = test_datagen.flow([x_test,x_test], y_test, batch_size=64)"
      ],
      "metadata": {
        "id": "4NEGPTzSRJp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input\n",
        "baseModel = VGG16(include_top=False,pooling='avg', input_tensor=Input(shape=(128, 128, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAcJ4wznchm4",
        "outputId": "35021c07-bc1e-41cb-c381-07fe4088ea71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.densenet import DenseNet169\n",
        "baseModel2= DenseNet169(include_top=False,pooling='avg', input_tensor=Input(shape=(128, 128, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkNwK6tHufWv",
        "outputId": "b4d94b47-1317-4e41-9201-fdb0ce181275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51877672/51877672 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import concatenate\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel2 = baseModel2.output\n",
        "\n",
        "headModel = concatenate([headModel, headModel2])\n",
        "headModel = Flatten(name=\"flatten\")(headModel2)\n",
        "headModel = Dense(256, activation='elu')(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation='softmax')(headModel)\n"
      ],
      "metadata": {
        "id": "1pmf15qCvOOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "model = Model(inputs=[baseModel.input,baseModel2.input], outputs=headModel)"
      ],
      "metadata": {
        "id": "zvZ3mv-wwyDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdKUyxh7x6Mg",
        "outputId": "e3aaf28c-cc05-4953-c6ad-4c09da0c0f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 134, 134, 3)  0          ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1/conv (Conv2D)            (None, 64, 64, 64)   9408        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " conv1/bn (BatchNormalization)  (None, 64, 64, 64)   256         ['conv1/conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1/relu (Activation)        (None, 64, 64, 64)   0           ['conv1/bn[0][0]']               \n",
            "                                                                                                  \n",
            " zero_padding2d_1 (ZeroPadding2  (None, 66, 66, 64)  0           ['conv1/relu[0][0]']             \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 32, 32, 64)   0           ['zero_padding2d_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 32, 32, 64)  256         ['pool1[0][0]']                  \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_0_relu (Activatio  (None, 32, 32, 64)  0           ['conv2_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 32, 32, 128)  8192        ['conv2_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_concat (Concatena  (None, 32, 32, 96)  0           ['pool1[0][0]',                  \n",
            " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_0_bn (BatchNormal  (None, 32, 32, 96)  384         ['conv2_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_0_relu (Activatio  (None, 32, 32, 96)  0           ['conv2_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 32, 32, 128)  12288       ['conv2_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_concat (Concatena  (None, 32, 32, 128)  0          ['conv2_block1_concat[0][0]',    \n",
            " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_0_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_0_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 32, 32, 128)  16384       ['conv2_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_concat (Concatena  (None, 32, 32, 160)  0          ['conv2_block2_concat[0][0]',    \n",
            " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_0_bn (BatchNormal  (None, 32, 32, 160)  640        ['conv2_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_0_relu (Activatio  (None, 32, 32, 160)  0          ['conv2_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_1_conv (Conv2D)   (None, 32, 32, 128)  20480       ['conv2_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block4_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block4_concat (Concatena  (None, 32, 32, 192)  0          ['conv2_block3_concat[0][0]',    \n",
            " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_0_bn (BatchNormal  (None, 32, 32, 192)  768        ['conv2_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_0_relu (Activatio  (None, 32, 32, 192)  0          ['conv2_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_1_conv (Conv2D)   (None, 32, 32, 128)  24576       ['conv2_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block5_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block5_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block5_concat (Concatena  (None, 32, 32, 224)  0          ['conv2_block4_concat[0][0]',    \n",
            " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_0_bn (BatchNormal  (None, 32, 32, 224)  896        ['conv2_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_0_relu (Activatio  (None, 32, 32, 224)  0          ['conv2_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_1_conv (Conv2D)   (None, 32, 32, 128)  28672       ['conv2_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv2_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block6_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv2_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block6_2_conv (Conv2D)   (None, 32, 32, 32)   36864       ['conv2_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block6_concat (Concatena  (None, 32, 32, 256)  0          ['conv2_block5_concat[0][0]',    \n",
            " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_bn (BatchNormalization)  (None, 32, 32, 256)  1024        ['conv2_block6_concat[0][0]']    \n",
            "                                                                                                  \n",
            " pool2_relu (Activation)        (None, 32, 32, 256)  0           ['pool2_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool2_conv (Conv2D)            (None, 32, 32, 128)  32768       ['pool2_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool2_pool (AveragePooling2D)  (None, 16, 16, 128)  0           ['pool2_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 16, 16, 128)  512        ['pool2_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_0_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 16, 16, 128)  16384       ['conv3_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_concat (Concatena  (None, 16, 16, 160)  0          ['pool2_pool[0][0]',             \n",
            " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_0_bn (BatchNormal  (None, 16, 16, 160)  640        ['conv3_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_0_relu (Activatio  (None, 16, 16, 160)  0          ['conv3_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 16, 16, 128)  20480       ['conv3_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_concat (Concatena  (None, 16, 16, 192)  0          ['conv3_block1_concat[0][0]',    \n",
            " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_0_bn (BatchNormal  (None, 16, 16, 192)  768        ['conv3_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_0_relu (Activatio  (None, 16, 16, 192)  0          ['conv3_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 16, 16, 128)  24576       ['conv3_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_concat (Concatena  (None, 16, 16, 224)  0          ['conv3_block2_concat[0][0]',    \n",
            " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_0_bn (BatchNormal  (None, 16, 16, 224)  896        ['conv3_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_0_relu (Activatio  (None, 16, 16, 224)  0          ['conv3_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 16, 16, 128)  28672       ['conv3_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_concat (Concatena  (None, 16, 16, 256)  0          ['conv3_block3_concat[0][0]',    \n",
            " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_0_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv3_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_0_relu (Activatio  (None, 16, 16, 256)  0          ['conv3_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_1_conv (Conv2D)   (None, 16, 16, 128)  32768       ['conv3_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block5_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block5_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block5_concat (Concatena  (None, 16, 16, 288)  0          ['conv3_block4_concat[0][0]',    \n",
            " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_0_bn (BatchNormal  (None, 16, 16, 288)  1152       ['conv3_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_0_relu (Activatio  (None, 16, 16, 288)  0          ['conv3_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_1_conv (Conv2D)   (None, 16, 16, 128)  36864       ['conv3_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block6_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block6_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block6_concat (Concatena  (None, 16, 16, 320)  0          ['conv3_block5_concat[0][0]',    \n",
            " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_0_bn (BatchNormal  (None, 16, 16, 320)  1280       ['conv3_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_0_relu (Activatio  (None, 16, 16, 320)  0          ['conv3_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_1_conv (Conv2D)   (None, 16, 16, 128)  40960       ['conv3_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block7_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block7_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block7_concat (Concatena  (None, 16, 16, 352)  0          ['conv3_block6_concat[0][0]',    \n",
            " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_0_bn (BatchNormal  (None, 16, 16, 352)  1408       ['conv3_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_0_relu (Activatio  (None, 16, 16, 352)  0          ['conv3_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_1_conv (Conv2D)   (None, 16, 16, 128)  45056       ['conv3_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block8_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block8_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block8_concat (Concatena  (None, 16, 16, 384)  0          ['conv3_block7_concat[0][0]',    \n",
            " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_0_bn (BatchNormal  (None, 16, 16, 384)  1536       ['conv3_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_0_relu (Activatio  (None, 16, 16, 384)  0          ['conv3_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_1_conv (Conv2D)   (None, 16, 16, 128)  49152       ['conv3_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_1_bn (BatchNormal  (None, 16, 16, 128)  512        ['conv3_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block9_1_relu (Activatio  (None, 16, 16, 128)  0          ['conv3_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block9_2_conv (Conv2D)   (None, 16, 16, 32)   36864       ['conv3_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block9_concat (Concatena  (None, 16, 16, 416)  0          ['conv3_block8_concat[0][0]',    \n",
            " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block10_0_bn (BatchNorma  (None, 16, 16, 416)  1664       ['conv3_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_0_relu (Activati  (None, 16, 16, 416)  0          ['conv3_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_1_conv (Conv2D)  (None, 16, 16, 128)  53248       ['conv3_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv3_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block10_1_relu (Activati  (None, 16, 16, 128)  0          ['conv3_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block10_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv3_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block10_concat (Concaten  (None, 16, 16, 448)  0          ['conv3_block9_concat[0][0]',    \n",
            " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_0_bn (BatchNorma  (None, 16, 16, 448)  1792       ['conv3_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_0_relu (Activati  (None, 16, 16, 448)  0          ['conv3_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_1_conv (Conv2D)  (None, 16, 16, 128)  57344       ['conv3_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv3_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block11_1_relu (Activati  (None, 16, 16, 128)  0          ['conv3_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block11_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv3_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block11_concat (Concaten  (None, 16, 16, 480)  0          ['conv3_block10_concat[0][0]',   \n",
            " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_0_bn (BatchNorma  (None, 16, 16, 480)  1920       ['conv3_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_0_relu (Activati  (None, 16, 16, 480)  0          ['conv3_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_1_conv (Conv2D)  (None, 16, 16, 128)  61440       ['conv3_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_1_bn (BatchNorma  (None, 16, 16, 128)  512        ['conv3_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv3_block12_1_relu (Activati  (None, 16, 16, 128)  0          ['conv3_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block12_2_conv (Conv2D)  (None, 16, 16, 32)   36864       ['conv3_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block12_concat (Concaten  (None, 16, 16, 512)  0          ['conv3_block11_concat[0][0]',   \n",
            " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_bn (BatchNormalization)  (None, 16, 16, 512)  2048        ['conv3_block12_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool3_relu (Activation)        (None, 16, 16, 512)  0           ['pool3_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool3_conv (Conv2D)            (None, 16, 16, 256)  131072      ['pool3_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool3_pool (AveragePooling2D)  (None, 8, 8, 256)    0           ['pool3_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['pool3_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_0_relu (Activatio  (None, 8, 8, 256)   0           ['conv4_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 8, 8, 128)    32768       ['conv4_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_concat (Concatena  (None, 8, 8, 288)   0           ['pool3_pool[0][0]',             \n",
            " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_0_bn (BatchNormal  (None, 8, 8, 288)   1152        ['conv4_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_0_relu (Activatio  (None, 8, 8, 288)   0           ['conv4_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 8, 8, 128)    36864       ['conv4_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_concat (Concatena  (None, 8, 8, 320)   0           ['conv4_block1_concat[0][0]',    \n",
            " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_0_bn (BatchNormal  (None, 8, 8, 320)   1280        ['conv4_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_0_relu (Activatio  (None, 8, 8, 320)   0           ['conv4_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 8, 8, 128)    40960       ['conv4_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_concat (Concatena  (None, 8, 8, 352)   0           ['conv4_block2_concat[0][0]',    \n",
            " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_0_bn (BatchNormal  (None, 8, 8, 352)   1408        ['conv4_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_0_relu (Activatio  (None, 8, 8, 352)   0           ['conv4_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 8, 8, 128)    45056       ['conv4_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_concat (Concatena  (None, 8, 8, 384)   0           ['conv4_block3_concat[0][0]',    \n",
            " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_0_bn (BatchNormal  (None, 8, 8, 384)   1536        ['conv4_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_0_relu (Activatio  (None, 8, 8, 384)   0           ['conv4_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 8, 8, 128)    49152       ['conv4_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_concat (Concatena  (None, 8, 8, 416)   0           ['conv4_block4_concat[0][0]',    \n",
            " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_0_bn (BatchNormal  (None, 8, 8, 416)   1664        ['conv4_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_0_relu (Activatio  (None, 8, 8, 416)   0           ['conv4_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 8, 8, 128)    53248       ['conv4_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_concat (Concatena  (None, 8, 8, 448)   0           ['conv4_block5_concat[0][0]',    \n",
            " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_0_bn (BatchNormal  (None, 8, 8, 448)   1792        ['conv4_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_0_relu (Activatio  (None, 8, 8, 448)   0           ['conv4_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_1_conv (Conv2D)   (None, 8, 8, 128)    57344       ['conv4_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block7_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block7_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block7_concat (Concatena  (None, 8, 8, 480)   0           ['conv4_block6_concat[0][0]',    \n",
            " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_0_bn (BatchNormal  (None, 8, 8, 480)   1920        ['conv4_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_0_relu (Activatio  (None, 8, 8, 480)   0           ['conv4_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_1_conv (Conv2D)   (None, 8, 8, 128)    61440       ['conv4_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block8_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block8_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block8_concat (Concatena  (None, 8, 8, 512)   0           ['conv4_block7_concat[0][0]',    \n",
            " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_0_bn (BatchNormal  (None, 8, 8, 512)   2048        ['conv4_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_0_relu (Activatio  (None, 8, 8, 512)   0           ['conv4_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_1_conv (Conv2D)   (None, 8, 8, 128)    65536       ['conv4_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv4_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block9_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv4_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block9_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv4_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block9_concat (Concatena  (None, 8, 8, 544)   0           ['conv4_block8_concat[0][0]',    \n",
            " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block10_0_bn (BatchNorma  (None, 8, 8, 544)   2176        ['conv4_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_0_relu (Activati  (None, 8, 8, 544)   0           ['conv4_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_1_conv (Conv2D)  (None, 8, 8, 128)    69632       ['conv4_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block10_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block10_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block10_concat (Concaten  (None, 8, 8, 576)   0           ['conv4_block9_concat[0][0]',    \n",
            " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_0_bn (BatchNorma  (None, 8, 8, 576)   2304        ['conv4_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_0_relu (Activati  (None, 8, 8, 576)   0           ['conv4_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_1_conv (Conv2D)  (None, 8, 8, 128)    73728       ['conv4_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block11_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block11_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block11_concat (Concaten  (None, 8, 8, 608)   0           ['conv4_block10_concat[0][0]',   \n",
            " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_0_bn (BatchNorma  (None, 8, 8, 608)   2432        ['conv4_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_0_relu (Activati  (None, 8, 8, 608)   0           ['conv4_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_1_conv (Conv2D)  (None, 8, 8, 128)    77824       ['conv4_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block12_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block12_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block12_concat (Concaten  (None, 8, 8, 640)   0           ['conv4_block11_concat[0][0]',   \n",
            " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_0_bn (BatchNorma  (None, 8, 8, 640)   2560        ['conv4_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_0_relu (Activati  (None, 8, 8, 640)   0           ['conv4_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_1_conv (Conv2D)  (None, 8, 8, 128)    81920       ['conv4_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block13_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block13_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block13_concat (Concaten  (None, 8, 8, 672)   0           ['conv4_block12_concat[0][0]',   \n",
            " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_0_bn (BatchNorma  (None, 8, 8, 672)   2688        ['conv4_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_0_relu (Activati  (None, 8, 8, 672)   0           ['conv4_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_1_conv (Conv2D)  (None, 8, 8, 128)    86016       ['conv4_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block14_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block14_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block14_concat (Concaten  (None, 8, 8, 704)   0           ['conv4_block13_concat[0][0]',   \n",
            " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_0_bn (BatchNorma  (None, 8, 8, 704)   2816        ['conv4_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_0_relu (Activati  (None, 8, 8, 704)   0           ['conv4_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_1_conv (Conv2D)  (None, 8, 8, 128)    90112       ['conv4_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block15_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block15_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block15_concat (Concaten  (None, 8, 8, 736)   0           ['conv4_block14_concat[0][0]',   \n",
            " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_0_bn (BatchNorma  (None, 8, 8, 736)   2944        ['conv4_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_0_relu (Activati  (None, 8, 8, 736)   0           ['conv4_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_1_conv (Conv2D)  (None, 8, 8, 128)    94208       ['conv4_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block16_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block16_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block16_concat (Concaten  (None, 8, 8, 768)   0           ['conv4_block15_concat[0][0]',   \n",
            " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_0_bn (BatchNorma  (None, 8, 8, 768)   3072        ['conv4_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_0_relu (Activati  (None, 8, 8, 768)   0           ['conv4_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_1_conv (Conv2D)  (None, 8, 8, 128)    98304       ['conv4_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block17_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block17_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block17_concat (Concaten  (None, 8, 8, 800)   0           ['conv4_block16_concat[0][0]',   \n",
            " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_0_bn (BatchNorma  (None, 8, 8, 800)   3200        ['conv4_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_0_relu (Activati  (None, 8, 8, 800)   0           ['conv4_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_1_conv (Conv2D)  (None, 8, 8, 128)    102400      ['conv4_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block18_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block18_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block18_concat (Concaten  (None, 8, 8, 832)   0           ['conv4_block17_concat[0][0]',   \n",
            " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_0_bn (BatchNorma  (None, 8, 8, 832)   3328        ['conv4_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_0_relu (Activati  (None, 8, 8, 832)   0           ['conv4_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_1_conv (Conv2D)  (None, 8, 8, 128)    106496      ['conv4_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block19_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block19_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block19_concat (Concaten  (None, 8, 8, 864)   0           ['conv4_block18_concat[0][0]',   \n",
            " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_0_bn (BatchNorma  (None, 8, 8, 864)   3456        ['conv4_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_0_relu (Activati  (None, 8, 8, 864)   0           ['conv4_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_1_conv (Conv2D)  (None, 8, 8, 128)    110592      ['conv4_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block20_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block20_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block20_concat (Concaten  (None, 8, 8, 896)   0           ['conv4_block19_concat[0][0]',   \n",
            " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_0_bn (BatchNorma  (None, 8, 8, 896)   3584        ['conv4_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_0_relu (Activati  (None, 8, 8, 896)   0           ['conv4_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_1_conv (Conv2D)  (None, 8, 8, 128)    114688      ['conv4_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block21_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block21_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block21_concat (Concaten  (None, 8, 8, 928)   0           ['conv4_block20_concat[0][0]',   \n",
            " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_0_bn (BatchNorma  (None, 8, 8, 928)   3712        ['conv4_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_0_relu (Activati  (None, 8, 8, 928)   0           ['conv4_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_1_conv (Conv2D)  (None, 8, 8, 128)    118784      ['conv4_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block22_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block22_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block22_concat (Concaten  (None, 8, 8, 960)   0           ['conv4_block21_concat[0][0]',   \n",
            " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_0_bn (BatchNorma  (None, 8, 8, 960)   3840        ['conv4_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_0_relu (Activati  (None, 8, 8, 960)   0           ['conv4_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_1_conv (Conv2D)  (None, 8, 8, 128)    122880      ['conv4_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block23_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block23_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block23_concat (Concaten  (None, 8, 8, 992)   0           ['conv4_block22_concat[0][0]',   \n",
            " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_0_bn (BatchNorma  (None, 8, 8, 992)   3968        ['conv4_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_0_relu (Activati  (None, 8, 8, 992)   0           ['conv4_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_1_conv (Conv2D)  (None, 8, 8, 128)    126976      ['conv4_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block24_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block24_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block24_concat (Concaten  (None, 8, 8, 1024)  0           ['conv4_block23_concat[0][0]',   \n",
            " ate)                                                             'conv4_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block25_0_bn (BatchNorma  (None, 8, 8, 1024)  4096        ['conv4_block24_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block25_0_relu (Activati  (None, 8, 8, 1024)  0           ['conv4_block25_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block25_1_conv (Conv2D)  (None, 8, 8, 128)    131072      ['conv4_block25_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block25_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block25_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block25_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block25_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block25_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block25_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block25_concat (Concaten  (None, 8, 8, 1056)  0           ['conv4_block24_concat[0][0]',   \n",
            " ate)                                                             'conv4_block25_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block26_0_bn (BatchNorma  (None, 8, 8, 1056)  4224        ['conv4_block25_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block26_0_relu (Activati  (None, 8, 8, 1056)  0           ['conv4_block26_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block26_1_conv (Conv2D)  (None, 8, 8, 128)    135168      ['conv4_block26_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block26_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block26_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block26_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block26_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block26_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block26_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block26_concat (Concaten  (None, 8, 8, 1088)  0           ['conv4_block25_concat[0][0]',   \n",
            " ate)                                                             'conv4_block26_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block27_0_bn (BatchNorma  (None, 8, 8, 1088)  4352        ['conv4_block26_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block27_0_relu (Activati  (None, 8, 8, 1088)  0           ['conv4_block27_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block27_1_conv (Conv2D)  (None, 8, 8, 128)    139264      ['conv4_block27_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block27_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block27_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block27_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block27_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block27_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block27_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block27_concat (Concaten  (None, 8, 8, 1120)  0           ['conv4_block26_concat[0][0]',   \n",
            " ate)                                                             'conv4_block27_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block28_0_bn (BatchNorma  (None, 8, 8, 1120)  4480        ['conv4_block27_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block28_0_relu (Activati  (None, 8, 8, 1120)  0           ['conv4_block28_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block28_1_conv (Conv2D)  (None, 8, 8, 128)    143360      ['conv4_block28_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block28_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block28_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block28_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block28_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block28_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block28_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block28_concat (Concaten  (None, 8, 8, 1152)  0           ['conv4_block27_concat[0][0]',   \n",
            " ate)                                                             'conv4_block28_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block29_0_bn (BatchNorma  (None, 8, 8, 1152)  4608        ['conv4_block28_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block29_0_relu (Activati  (None, 8, 8, 1152)  0           ['conv4_block29_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block29_1_conv (Conv2D)  (None, 8, 8, 128)    147456      ['conv4_block29_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block29_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block29_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block29_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block29_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block29_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block29_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block29_concat (Concaten  (None, 8, 8, 1184)  0           ['conv4_block28_concat[0][0]',   \n",
            " ate)                                                             'conv4_block29_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block30_0_bn (BatchNorma  (None, 8, 8, 1184)  4736        ['conv4_block29_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block30_0_relu (Activati  (None, 8, 8, 1184)  0           ['conv4_block30_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block30_1_conv (Conv2D)  (None, 8, 8, 128)    151552      ['conv4_block30_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block30_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block30_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block30_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block30_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block30_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block30_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block30_concat (Concaten  (None, 8, 8, 1216)  0           ['conv4_block29_concat[0][0]',   \n",
            " ate)                                                             'conv4_block30_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block31_0_bn (BatchNorma  (None, 8, 8, 1216)  4864        ['conv4_block30_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block31_0_relu (Activati  (None, 8, 8, 1216)  0           ['conv4_block31_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block31_1_conv (Conv2D)  (None, 8, 8, 128)    155648      ['conv4_block31_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block31_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block31_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block31_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block31_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block31_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block31_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block31_concat (Concaten  (None, 8, 8, 1248)  0           ['conv4_block30_concat[0][0]',   \n",
            " ate)                                                             'conv4_block31_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block32_0_bn (BatchNorma  (None, 8, 8, 1248)  4992        ['conv4_block31_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block32_0_relu (Activati  (None, 8, 8, 1248)  0           ['conv4_block32_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block32_1_conv (Conv2D)  (None, 8, 8, 128)    159744      ['conv4_block32_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block32_1_bn (BatchNorma  (None, 8, 8, 128)   512         ['conv4_block32_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv4_block32_1_relu (Activati  (None, 8, 8, 128)   0           ['conv4_block32_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block32_2_conv (Conv2D)  (None, 8, 8, 32)     36864       ['conv4_block32_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block32_concat (Concaten  (None, 8, 8, 1280)  0           ['conv4_block31_concat[0][0]',   \n",
            " ate)                                                             'conv4_block32_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_bn (BatchNormalization)  (None, 8, 8, 1280)   5120        ['conv4_block32_concat[0][0]']   \n",
            "                                                                                                  \n",
            " pool4_relu (Activation)        (None, 8, 8, 1280)   0           ['pool4_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool4_conv (Conv2D)            (None, 8, 8, 640)    819200      ['pool4_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool4_pool (AveragePooling2D)  (None, 4, 4, 640)    0           ['pool4_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 4, 4, 640)   2560        ['pool4_pool[0][0]']             \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_0_relu (Activatio  (None, 4, 4, 640)   0           ['conv5_block1_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 4, 4, 128)    81920       ['conv5_block1_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_concat (Concatena  (None, 4, 4, 672)   0           ['pool4_pool[0][0]',             \n",
            " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_0_bn (BatchNormal  (None, 4, 4, 672)   2688        ['conv5_block1_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_0_relu (Activatio  (None, 4, 4, 672)   0           ['conv5_block2_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 4, 4, 128)    86016       ['conv5_block2_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_concat (Concatena  (None, 4, 4, 704)   0           ['conv5_block1_concat[0][0]',    \n",
            " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_0_bn (BatchNormal  (None, 4, 4, 704)   2816        ['conv5_block2_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_0_relu (Activatio  (None, 4, 4, 704)   0           ['conv5_block3_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 4, 4, 128)    90112       ['conv5_block3_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_concat (Concatena  (None, 4, 4, 736)   0           ['conv5_block2_concat[0][0]',    \n",
            " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_0_bn (BatchNormal  (None, 4, 4, 736)   2944        ['conv5_block3_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_0_relu (Activatio  (None, 4, 4, 736)   0           ['conv5_block4_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_1_conv (Conv2D)   (None, 4, 4, 128)    94208       ['conv5_block4_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block4_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block4_concat (Concatena  (None, 4, 4, 768)   0           ['conv5_block3_concat[0][0]',    \n",
            " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_0_bn (BatchNormal  (None, 4, 4, 768)   3072        ['conv5_block4_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_0_relu (Activatio  (None, 4, 4, 768)   0           ['conv5_block5_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_1_conv (Conv2D)   (None, 4, 4, 128)    98304       ['conv5_block5_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block5_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block5_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block5_concat (Concatena  (None, 4, 4, 800)   0           ['conv5_block4_concat[0][0]',    \n",
            " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_0_bn (BatchNormal  (None, 4, 4, 800)   3200        ['conv5_block5_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_0_relu (Activatio  (None, 4, 4, 800)   0           ['conv5_block6_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_1_conv (Conv2D)   (None, 4, 4, 128)    102400      ['conv5_block6_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block6_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block6_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block6_concat (Concatena  (None, 4, 4, 832)   0           ['conv5_block5_concat[0][0]',    \n",
            " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_0_bn (BatchNormal  (None, 4, 4, 832)   3328        ['conv5_block6_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_0_relu (Activatio  (None, 4, 4, 832)   0           ['conv5_block7_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_1_conv (Conv2D)   (None, 4, 4, 128)    106496      ['conv5_block7_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block7_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block7_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block7_concat (Concatena  (None, 4, 4, 864)   0           ['conv5_block6_concat[0][0]',    \n",
            " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_0_bn (BatchNormal  (None, 4, 4, 864)   3456        ['conv5_block7_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_0_relu (Activatio  (None, 4, 4, 864)   0           ['conv5_block8_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_1_conv (Conv2D)   (None, 4, 4, 128)    110592      ['conv5_block8_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block8_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block8_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block8_concat (Concatena  (None, 4, 4, 896)   0           ['conv5_block7_concat[0][0]',    \n",
            " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_0_bn (BatchNormal  (None, 4, 4, 896)   3584        ['conv5_block8_concat[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_0_relu (Activatio  (None, 4, 4, 896)   0           ['conv5_block9_0_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_1_conv (Conv2D)   (None, 4, 4, 128)    114688      ['conv5_block9_0_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block9_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block9_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block9_concat (Concatena  (None, 4, 4, 928)   0           ['conv5_block8_concat[0][0]',    \n",
            " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block10_0_bn (BatchNorma  (None, 4, 4, 928)   3712        ['conv5_block9_concat[0][0]']    \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_0_relu (Activati  (None, 4, 4, 928)   0           ['conv5_block10_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_1_conv (Conv2D)  (None, 4, 4, 128)    118784      ['conv5_block10_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block10_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block10_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block10_concat (Concaten  (None, 4, 4, 960)   0           ['conv5_block9_concat[0][0]',    \n",
            " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_0_bn (BatchNorma  (None, 4, 4, 960)   3840        ['conv5_block10_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_0_relu (Activati  (None, 4, 4, 960)   0           ['conv5_block11_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_1_conv (Conv2D)  (None, 4, 4, 128)    122880      ['conv5_block11_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block11_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block11_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block11_concat (Concaten  (None, 4, 4, 992)   0           ['conv5_block10_concat[0][0]',   \n",
            " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_0_bn (BatchNorma  (None, 4, 4, 992)   3968        ['conv5_block11_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_0_relu (Activati  (None, 4, 4, 992)   0           ['conv5_block12_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_1_conv (Conv2D)  (None, 4, 4, 128)    126976      ['conv5_block12_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block12_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block12_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block12_concat (Concaten  (None, 4, 4, 1024)  0           ['conv5_block11_concat[0][0]',   \n",
            " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_0_bn (BatchNorma  (None, 4, 4, 1024)  4096        ['conv5_block12_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_0_relu (Activati  (None, 4, 4, 1024)  0           ['conv5_block13_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_1_conv (Conv2D)  (None, 4, 4, 128)    131072      ['conv5_block13_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block13_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block13_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block13_concat (Concaten  (None, 4, 4, 1056)  0           ['conv5_block12_concat[0][0]',   \n",
            " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_0_bn (BatchNorma  (None, 4, 4, 1056)  4224        ['conv5_block13_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_0_relu (Activati  (None, 4, 4, 1056)  0           ['conv5_block14_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_1_conv (Conv2D)  (None, 4, 4, 128)    135168      ['conv5_block14_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block14_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block14_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block14_concat (Concaten  (None, 4, 4, 1088)  0           ['conv5_block13_concat[0][0]',   \n",
            " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_0_bn (BatchNorma  (None, 4, 4, 1088)  4352        ['conv5_block14_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_0_relu (Activati  (None, 4, 4, 1088)  0           ['conv5_block15_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_1_conv (Conv2D)  (None, 4, 4, 128)    139264      ['conv5_block15_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block15_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block15_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block15_concat (Concaten  (None, 4, 4, 1120)  0           ['conv5_block14_concat[0][0]',   \n",
            " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_0_bn (BatchNorma  (None, 4, 4, 1120)  4480        ['conv5_block15_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_0_relu (Activati  (None, 4, 4, 1120)  0           ['conv5_block16_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_1_conv (Conv2D)  (None, 4, 4, 128)    143360      ['conv5_block16_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block16_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block16_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block16_concat (Concaten  (None, 4, 4, 1152)  0           ['conv5_block15_concat[0][0]',   \n",
            " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block17_0_bn (BatchNorma  (None, 4, 4, 1152)  4608        ['conv5_block16_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block17_0_relu (Activati  (None, 4, 4, 1152)  0           ['conv5_block17_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block17_1_conv (Conv2D)  (None, 4, 4, 128)    147456      ['conv5_block17_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block17_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block17_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block17_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block17_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block17_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block17_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block17_concat (Concaten  (None, 4, 4, 1184)  0           ['conv5_block16_concat[0][0]',   \n",
            " ate)                                                             'conv5_block17_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block18_0_bn (BatchNorma  (None, 4, 4, 1184)  4736        ['conv5_block17_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block18_0_relu (Activati  (None, 4, 4, 1184)  0           ['conv5_block18_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block18_1_conv (Conv2D)  (None, 4, 4, 128)    151552      ['conv5_block18_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block18_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block18_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block18_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block18_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block18_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block18_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block18_concat (Concaten  (None, 4, 4, 1216)  0           ['conv5_block17_concat[0][0]',   \n",
            " ate)                                                             'conv5_block18_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block19_0_bn (BatchNorma  (None, 4, 4, 1216)  4864        ['conv5_block18_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block19_0_relu (Activati  (None, 4, 4, 1216)  0           ['conv5_block19_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block19_1_conv (Conv2D)  (None, 4, 4, 128)    155648      ['conv5_block19_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block19_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block19_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block19_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block19_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block19_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block19_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block19_concat (Concaten  (None, 4, 4, 1248)  0           ['conv5_block18_concat[0][0]',   \n",
            " ate)                                                             'conv5_block19_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block20_0_bn (BatchNorma  (None, 4, 4, 1248)  4992        ['conv5_block19_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block20_0_relu (Activati  (None, 4, 4, 1248)  0           ['conv5_block20_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block20_1_conv (Conv2D)  (None, 4, 4, 128)    159744      ['conv5_block20_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block20_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block20_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block20_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block20_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block20_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block20_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block20_concat (Concaten  (None, 4, 4, 1280)  0           ['conv5_block19_concat[0][0]',   \n",
            " ate)                                                             'conv5_block20_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block21_0_bn (BatchNorma  (None, 4, 4, 1280)  5120        ['conv5_block20_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block21_0_relu (Activati  (None, 4, 4, 1280)  0           ['conv5_block21_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block21_1_conv (Conv2D)  (None, 4, 4, 128)    163840      ['conv5_block21_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block21_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block21_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block21_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block21_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block21_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block21_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block21_concat (Concaten  (None, 4, 4, 1312)  0           ['conv5_block20_concat[0][0]',   \n",
            " ate)                                                             'conv5_block21_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block22_0_bn (BatchNorma  (None, 4, 4, 1312)  5248        ['conv5_block21_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block22_0_relu (Activati  (None, 4, 4, 1312)  0           ['conv5_block22_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block22_1_conv (Conv2D)  (None, 4, 4, 128)    167936      ['conv5_block22_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block22_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block22_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block22_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block22_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block22_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block22_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block22_concat (Concaten  (None, 4, 4, 1344)  0           ['conv5_block21_concat[0][0]',   \n",
            " ate)                                                             'conv5_block22_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block23_0_bn (BatchNorma  (None, 4, 4, 1344)  5376        ['conv5_block22_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block23_0_relu (Activati  (None, 4, 4, 1344)  0           ['conv5_block23_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block23_1_conv (Conv2D)  (None, 4, 4, 128)    172032      ['conv5_block23_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block23_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block23_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block23_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block23_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block23_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block23_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block23_concat (Concaten  (None, 4, 4, 1376)  0           ['conv5_block22_concat[0][0]',   \n",
            " ate)                                                             'conv5_block23_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block24_0_bn (BatchNorma  (None, 4, 4, 1376)  5504        ['conv5_block23_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block24_0_relu (Activati  (None, 4, 4, 1376)  0           ['conv5_block24_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block24_1_conv (Conv2D)  (None, 4, 4, 128)    176128      ['conv5_block24_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block24_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block24_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block24_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block24_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block24_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block24_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block24_concat (Concaten  (None, 4, 4, 1408)  0           ['conv5_block23_concat[0][0]',   \n",
            " ate)                                                             'conv5_block24_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block25_0_bn (BatchNorma  (None, 4, 4, 1408)  5632        ['conv5_block24_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block25_0_relu (Activati  (None, 4, 4, 1408)  0           ['conv5_block25_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block25_1_conv (Conv2D)  (None, 4, 4, 128)    180224      ['conv5_block25_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block25_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block25_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block25_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block25_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block25_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block25_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block25_concat (Concaten  (None, 4, 4, 1440)  0           ['conv5_block24_concat[0][0]',   \n",
            " ate)                                                             'conv5_block25_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block26_0_bn (BatchNorma  (None, 4, 4, 1440)  5760        ['conv5_block25_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block26_0_relu (Activati  (None, 4, 4, 1440)  0           ['conv5_block26_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block26_1_conv (Conv2D)  (None, 4, 4, 128)    184320      ['conv5_block26_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block26_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block26_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block26_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block26_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block26_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block26_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block26_concat (Concaten  (None, 4, 4, 1472)  0           ['conv5_block25_concat[0][0]',   \n",
            " ate)                                                             'conv5_block26_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block27_0_bn (BatchNorma  (None, 4, 4, 1472)  5888        ['conv5_block26_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block27_0_relu (Activati  (None, 4, 4, 1472)  0           ['conv5_block27_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block27_1_conv (Conv2D)  (None, 4, 4, 128)    188416      ['conv5_block27_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block27_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block27_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block27_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block27_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block27_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block27_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block27_concat (Concaten  (None, 4, 4, 1504)  0           ['conv5_block26_concat[0][0]',   \n",
            " ate)                                                             'conv5_block27_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block28_0_bn (BatchNorma  (None, 4, 4, 1504)  6016        ['conv5_block27_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block28_0_relu (Activati  (None, 4, 4, 1504)  0           ['conv5_block28_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block28_1_conv (Conv2D)  (None, 4, 4, 128)    192512      ['conv5_block28_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block28_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block28_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block28_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block28_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block28_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block28_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block28_concat (Concaten  (None, 4, 4, 1536)  0           ['conv5_block27_concat[0][0]',   \n",
            " ate)                                                             'conv5_block28_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block29_0_bn (BatchNorma  (None, 4, 4, 1536)  6144        ['conv5_block28_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block29_0_relu (Activati  (None, 4, 4, 1536)  0           ['conv5_block29_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block29_1_conv (Conv2D)  (None, 4, 4, 128)    196608      ['conv5_block29_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block29_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block29_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block29_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block29_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block29_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block29_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block29_concat (Concaten  (None, 4, 4, 1568)  0           ['conv5_block28_concat[0][0]',   \n",
            " ate)                                                             'conv5_block29_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block30_0_bn (BatchNorma  (None, 4, 4, 1568)  6272        ['conv5_block29_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block30_0_relu (Activati  (None, 4, 4, 1568)  0           ['conv5_block30_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block30_1_conv (Conv2D)  (None, 4, 4, 128)    200704      ['conv5_block30_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block30_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block30_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block30_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block30_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block30_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block30_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block30_concat (Concaten  (None, 4, 4, 1600)  0           ['conv5_block29_concat[0][0]',   \n",
            " ate)                                                             'conv5_block30_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block31_0_bn (BatchNorma  (None, 4, 4, 1600)  6400        ['conv5_block30_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block31_0_relu (Activati  (None, 4, 4, 1600)  0           ['conv5_block31_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block31_1_conv (Conv2D)  (None, 4, 4, 128)    204800      ['conv5_block31_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block31_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block31_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block31_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block31_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block31_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block31_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block31_concat (Concaten  (None, 4, 4, 1632)  0           ['conv5_block30_concat[0][0]',   \n",
            " ate)                                                             'conv5_block31_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block32_0_bn (BatchNorma  (None, 4, 4, 1632)  6528        ['conv5_block31_concat[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block32_0_relu (Activati  (None, 4, 4, 1632)  0           ['conv5_block32_0_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block32_1_conv (Conv2D)  (None, 4, 4, 128)    208896      ['conv5_block32_0_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block32_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv5_block32_1_conv[0][0]']   \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " conv5_block32_1_relu (Activati  (None, 4, 4, 128)   0           ['conv5_block32_1_bn[0][0]']     \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv5_block32_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv5_block32_1_relu[0][0]']   \n",
            "                                                                                                  \n",
            " conv5_block32_concat (Concaten  (None, 4, 4, 1664)  0           ['conv5_block31_concat[0][0]',   \n",
            " ate)                                                             'conv5_block32_2_conv[0][0]']   \n",
            "                                                                                                  \n",
            " bn (BatchNormalization)        (None, 4, 4, 1664)   6656        ['conv5_block32_concat[0][0]']   \n",
            "                                                                                                  \n",
            " relu (Activation)              (None, 4, 4, 1664)   0           ['bn[0][0]']                     \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 1664)        0           ['relu[0][0]']                   \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1664)         0           ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          426240      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 2)            514         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 13,069,634\n",
            "Trainable params: 12,911,234\n",
            "Non-trainable params: 158,400\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(optimizer=Adam(lr=1e-3), \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "SX3r0oNN1D2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c877ede-89b7-4e6d-e2c2-0d857deefe9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('val_acc') > 0.81):   \n",
        "          print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(0.81*100))   \n",
        "          self.model.stop_training = True"
      ],
      "metadata": {
        "id": "DWQWpLg_GXWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "siJvSgBLGfHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H1 = model.fit(train_iterator, epochs=150, validation_data=val_iterator, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBIBGnt82GIf",
        "outputId": "357f1cd3-7023-486a-99c2-8952e4bdf830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "49/49 [==============================] - 70s 606ms/step - loss: 0.8950 - acc: 0.6095 - val_loss: 31.2130 - val_acc: 0.5000\n",
            "Epoch 2/150\n",
            "49/49 [==============================] - 20s 408ms/step - loss: 0.6084 - acc: 0.7115 - val_loss: 1.7617 - val_acc: 0.5249\n",
            "Epoch 3/150\n",
            "49/49 [==============================] - 20s 398ms/step - loss: 0.5432 - acc: 0.7518 - val_loss: 44.7680 - val_acc: 0.4955\n",
            "Epoch 4/150\n",
            "49/49 [==============================] - 20s 398ms/step - loss: 0.4652 - acc: 0.7807 - val_loss: 2.5464 - val_acc: 0.6810\n",
            "Epoch 5/150\n",
            "49/49 [==============================] - 20s 400ms/step - loss: 0.4403 - acc: 0.8049 - val_loss: 0.5645 - val_acc: 0.7964\n",
            "Epoch 6/150\n",
            "49/49 [==============================] - 20s 398ms/step - loss: 0.3930 - acc: 0.8278 - val_loss: 0.9263 - val_acc: 0.7443\n",
            "Epoch 7/150\n",
            "49/49 [==============================] - 20s 401ms/step - loss: 0.3377 - acc: 0.8529 - val_loss: 0.6464 - val_acc: 0.7579\n",
            "Epoch 8/150\n",
            "49/49 [==============================] - 20s 398ms/step - loss: 0.3232 - acc: 0.8651 - val_loss: 1.2007 - val_acc: 0.6471\n",
            "Epoch 9/150\n",
            "49/49 [==============================] - 20s 397ms/step - loss: 0.3061 - acc: 0.8667 - val_loss: 0.6514 - val_acc: 0.6199\n",
            "Epoch 10/150\n",
            "49/49 [==============================] - 21s 416ms/step - loss: 0.3001 - acc: 0.8731 - val_loss: 1.2553 - val_acc: 0.5000\n",
            "Epoch 11/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.3527 - acc: 0.8422 - val_loss: 1.1705 - val_acc: 0.7104\n",
            "Epoch 12/150\n",
            "49/49 [==============================] - 19s 395ms/step - loss: 0.2691 - acc: 0.8896 - val_loss: 95.6806 - val_acc: 0.5204\n",
            "Epoch 13/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 0.2183 - acc: 0.9111 - val_loss: 0.9883 - val_acc: 0.7579\n",
            "Epoch 14/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 0.1719 - acc: 0.9301 - val_loss: 3.6715 - val_acc: 0.6719\n",
            "Epoch 15/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 0.1378 - acc: 0.9504 - val_loss: 1.5873 - val_acc: 0.6923\n",
            "Epoch 16/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.1024 - acc: 0.9617 - val_loss: 1.1018 - val_acc: 0.7624\n",
            "Epoch 17/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 0.1101 - acc: 0.9591 - val_loss: 1.1016 - val_acc: 0.7014\n",
            "Epoch 18/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 0.0735 - acc: 0.9733 - val_loss: 1.0047 - val_acc: 0.7647\n",
            "Epoch 19/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0860 - acc: 0.9678 - val_loss: 1.6187 - val_acc: 0.8009\n",
            "Epoch 20/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 0.0898 - acc: 0.9646 - val_loss: 0.9072 - val_acc: 0.7670\n",
            "Epoch 21/150\n",
            "49/49 [==============================] - 20s 411ms/step - loss: 0.0602 - acc: 0.9781 - val_loss: 0.9252 - val_acc: 0.7828\n",
            "Epoch 22/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 0.0448 - acc: 0.9839 - val_loss: 1.1041 - val_acc: 0.7738\n",
            "Epoch 23/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0407 - acc: 0.9845 - val_loss: 1.7866 - val_acc: 0.7534\n",
            "Epoch 24/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 0.0828 - acc: 0.9710 - val_loss: 1.7783 - val_acc: 0.7376\n",
            "Epoch 25/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0528 - acc: 0.9797 - val_loss: 1.7127 - val_acc: 0.7036\n",
            "Epoch 26/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0620 - acc: 0.9749 - val_loss: 1.0615 - val_acc: 0.7489\n",
            "Epoch 27/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 0.0443 - acc: 0.9845 - val_loss: 1.1398 - val_acc: 0.7670\n",
            "Epoch 28/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 0.0523 - acc: 0.9797 - val_loss: 0.9766 - val_acc: 0.7828\n",
            "Epoch 29/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 0.0308 - acc: 0.9887 - val_loss: 1.2504 - val_acc: 0.7738\n",
            "Epoch 30/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 0.0410 - acc: 0.9852 - val_loss: 1.2824 - val_acc: 0.7624\n",
            "Epoch 31/150\n",
            "49/49 [==============================] - 20s 413ms/step - loss: 0.0479 - acc: 0.9839 - val_loss: 0.9495 - val_acc: 0.7579\n",
            "Epoch 32/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 0.0128 - acc: 0.9955 - val_loss: 1.0226 - val_acc: 0.7919\n",
            "Epoch 33/150\n",
            "49/49 [==============================] - 20s 400ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 1.0836 - val_acc: 0.7941\n",
            "Epoch 34/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 1.2847 - val_acc: 0.7692\n",
            "Epoch 35/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 1.4548 - val_acc: 0.7783\n",
            "Epoch 36/150\n",
            "49/49 [==============================] - 19s 398ms/step - loss: 0.0574 - acc: 0.9788 - val_loss: 2.6632 - val_acc: 0.7240\n",
            "Epoch 37/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 0.0955 - acc: 0.9643 - val_loss: 1.5850 - val_acc: 0.7715\n",
            "Epoch 38/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 0.0241 - acc: 0.9936 - val_loss: 1.6907 - val_acc: 0.7308\n",
            "Epoch 39/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 0.0355 - acc: 0.9865 - val_loss: 1.4351 - val_acc: 0.7624\n",
            "Epoch 40/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 0.0404 - acc: 0.9849 - val_loss: 0.9387 - val_acc: 0.7692\n",
            "Epoch 41/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0307 - acc: 0.9903 - val_loss: 1.0798 - val_acc: 0.7670\n",
            "Epoch 42/150\n",
            "49/49 [==============================] - 20s 410ms/step - loss: 0.0374 - acc: 0.9839 - val_loss: 1.3071 - val_acc: 0.7534\n",
            "Epoch 43/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 0.0418 - acc: 0.9855 - val_loss: 1.0538 - val_acc: 0.7534\n",
            "Epoch 44/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 0.0218 - acc: 0.9923 - val_loss: 1.2890 - val_acc: 0.7511\n",
            "Epoch 45/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 0.0278 - acc: 0.9894 - val_loss: 0.9704 - val_acc: 0.7851\n",
            "Epoch 46/150\n",
            "49/49 [==============================] - 19s 399ms/step - loss: 0.0368 - acc: 0.9855 - val_loss: 1.3127 - val_acc: 0.7828\n",
            "Epoch 47/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 0.0352 - acc: 0.9874 - val_loss: 1.7971 - val_acc: 0.7285\n",
            "Epoch 48/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0209 - acc: 0.9916 - val_loss: 1.1189 - val_acc: 0.7760\n",
            "Epoch 49/150\n",
            "49/49 [==============================] - 19s 397ms/step - loss: 0.0151 - acc: 0.9945 - val_loss: 1.2749 - val_acc: 0.7738\n",
            "Epoch 50/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0127 - acc: 0.9965 - val_loss: 1.0491 - val_acc: 0.7828\n",
            "Epoch 51/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 0.0471 - acc: 0.9858 - val_loss: 0.9892 - val_acc: 0.7602\n",
            "Epoch 52/150\n",
            "49/49 [==============================] - 20s 412ms/step - loss: 0.0195 - acc: 0.9923 - val_loss: 1.1368 - val_acc: 0.7964\n",
            "Epoch 53/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 0.0411 - acc: 0.9874 - val_loss: 1.2062 - val_acc: 0.7353\n",
            "Epoch 54/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 0.0237 - acc: 0.9929 - val_loss: 1.3625 - val_acc: 0.7715\n",
            "Epoch 55/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 1.4641 - val_acc: 0.7783\n",
            "Epoch 56/150\n",
            "49/49 [==============================] - 19s 395ms/step - loss: 0.0217 - acc: 0.9936 - val_loss: 1.2680 - val_acc: 0.7986\n",
            "Epoch 57/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 0.0522 - acc: 0.9791 - val_loss: 1.3269 - val_acc: 0.7760\n",
            "Epoch 58/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 0.0171 - acc: 0.9939 - val_loss: 1.1227 - val_acc: 0.7783\n",
            "Epoch 59/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 0.0074 - acc: 0.9987 - val_loss: 1.5065 - val_acc: 0.7738\n",
            "Epoch 60/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 1.4060 - val_acc: 0.7783\n",
            "Epoch 61/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 6.1144e-04 - acc: 1.0000 - val_loss: 1.4934 - val_acc: 0.7896\n",
            "Epoch 62/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 4.3311e-04 - acc: 1.0000 - val_loss: 1.5006 - val_acc: 0.8032\n",
            "Epoch 63/150\n",
            "49/49 [==============================] - 20s 410ms/step - loss: 2.1454e-04 - acc: 1.0000 - val_loss: 1.5321 - val_acc: 0.7896\n",
            "Epoch 64/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 8.3893e-05 - acc: 1.0000 - val_loss: 1.5375 - val_acc: 0.7851\n",
            "Epoch 65/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 7.1112e-05 - acc: 1.0000 - val_loss: 1.5532 - val_acc: 0.7919\n",
            "Epoch 66/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 5.1702e-05 - acc: 1.0000 - val_loss: 1.5542 - val_acc: 0.7919\n",
            "Epoch 67/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 3.4902e-05 - acc: 1.0000 - val_loss: 1.5641 - val_acc: 0.7873\n",
            "Epoch 68/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 2.9498e-05 - acc: 1.0000 - val_loss: 1.5735 - val_acc: 0.7873\n",
            "Epoch 69/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 5.1457e-05 - acc: 1.0000 - val_loss: 1.5771 - val_acc: 0.7873\n",
            "Epoch 70/150\n",
            "49/49 [==============================] - 19s 389ms/step - loss: 2.6848e-05 - acc: 1.0000 - val_loss: 1.5856 - val_acc: 0.7873\n",
            "Epoch 71/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 4.4492e-05 - acc: 1.0000 - val_loss: 1.6101 - val_acc: 0.7941\n",
            "Epoch 72/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 2.4006e-05 - acc: 1.0000 - val_loss: 1.6192 - val_acc: 0.7919\n",
            "Epoch 73/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 1.8473e-05 - acc: 1.0000 - val_loss: 1.6267 - val_acc: 0.7941\n",
            "Epoch 74/150\n",
            "49/49 [==============================] - 20s 410ms/step - loss: 2.0010e-05 - acc: 1.0000 - val_loss: 1.6338 - val_acc: 0.7919\n",
            "Epoch 75/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 3.7250e-05 - acc: 1.0000 - val_loss: 1.6553 - val_acc: 0.7986\n",
            "Epoch 76/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 2.5616e-05 - acc: 1.0000 - val_loss: 1.6640 - val_acc: 0.7941\n",
            "Epoch 77/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 1.4402e-05 - acc: 1.0000 - val_loss: 1.6693 - val_acc: 0.7941\n",
            "Epoch 78/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 1.5595e-05 - acc: 1.0000 - val_loss: 1.6750 - val_acc: 0.7964\n",
            "Epoch 79/150\n",
            "49/49 [==============================] - 19s 390ms/step - loss: 8.0836e-06 - acc: 1.0000 - val_loss: 1.6816 - val_acc: 0.7964\n",
            "Epoch 80/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 1.0558e-05 - acc: 1.0000 - val_loss: 1.6896 - val_acc: 0.7964\n",
            "Epoch 81/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 1.2263e-05 - acc: 1.0000 - val_loss: 1.7006 - val_acc: 0.7941\n",
            "Epoch 82/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 7.2167e-06 - acc: 1.0000 - val_loss: 1.7070 - val_acc: 0.7941\n",
            "Epoch 83/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 1.2671e-05 - acc: 1.0000 - val_loss: 1.7087 - val_acc: 0.7964\n",
            "Epoch 84/150\n",
            "49/49 [==============================] - 20s 411ms/step - loss: 2.7322e-05 - acc: 1.0000 - val_loss: 1.7239 - val_acc: 0.7941\n",
            "Epoch 85/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 9.3046e-06 - acc: 1.0000 - val_loss: 1.7354 - val_acc: 0.7919\n",
            "Epoch 86/150\n",
            "49/49 [==============================] - 20s 397ms/step - loss: 7.6775e-06 - acc: 1.0000 - val_loss: 1.7457 - val_acc: 0.7919\n",
            "Epoch 87/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 5.5094e-06 - acc: 1.0000 - val_loss: 1.7539 - val_acc: 0.7941\n",
            "Epoch 88/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 6.6651e-06 - acc: 1.0000 - val_loss: 1.7638 - val_acc: 0.7919\n",
            "Epoch 89/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 1.2313e-05 - acc: 1.0000 - val_loss: 1.7876 - val_acc: 0.7896\n",
            "Epoch 90/150\n",
            "49/49 [==============================] - 20s 394ms/step - loss: 7.3981e-06 - acc: 1.0000 - val_loss: 1.7879 - val_acc: 0.7941\n",
            "Epoch 91/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 1.3158e-05 - acc: 1.0000 - val_loss: 1.7905 - val_acc: 0.7964\n",
            "Epoch 92/150\n",
            "49/49 [==============================] - 19s 395ms/step - loss: 4.8804e-06 - acc: 1.0000 - val_loss: 1.7976 - val_acc: 0.7919\n",
            "Epoch 93/150\n",
            "49/49 [==============================] - 19s 395ms/step - loss: 5.7132e-06 - acc: 1.0000 - val_loss: 1.8055 - val_acc: 0.7919\n",
            "Epoch 94/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 1.4572e-05 - acc: 1.0000 - val_loss: 1.8209 - val_acc: 0.7896\n",
            "Epoch 95/150\n",
            "49/49 [==============================] - 20s 413ms/step - loss: 4.0219e-06 - acc: 1.0000 - val_loss: 1.8242 - val_acc: 0.7941\n",
            "Epoch 96/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 5.4345e-06 - acc: 1.0000 - val_loss: 1.8277 - val_acc: 0.7941\n",
            "Epoch 97/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 4.4600e-06 - acc: 1.0000 - val_loss: 1.8304 - val_acc: 0.7919\n",
            "Epoch 98/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 3.7461e-06 - acc: 1.0000 - val_loss: 1.8346 - val_acc: 0.7919\n",
            "Epoch 99/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 1.3106e-05 - acc: 1.0000 - val_loss: 1.8235 - val_acc: 0.8009\n",
            "Epoch 100/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 1.0741e-05 - acc: 1.0000 - val_loss: 1.8367 - val_acc: 0.7896\n",
            "Epoch 101/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 4.3957e-06 - acc: 1.0000 - val_loss: 1.8422 - val_acc: 0.7964\n",
            "Epoch 102/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 2.8965e-06 - acc: 1.0000 - val_loss: 1.8472 - val_acc: 0.7964\n",
            "Epoch 103/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 4.4950e-06 - acc: 1.0000 - val_loss: 1.8489 - val_acc: 0.7986\n",
            "Epoch 104/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 3.5700e-06 - acc: 1.0000 - val_loss: 1.8543 - val_acc: 0.7986\n",
            "Epoch 105/150\n",
            "49/49 [==============================] - 20s 394ms/step - loss: 3.9369e-06 - acc: 1.0000 - val_loss: 1.8639 - val_acc: 0.7964\n",
            "Epoch 106/150\n",
            "49/49 [==============================] - 20s 411ms/step - loss: 3.0072e-06 - acc: 1.0000 - val_loss: 1.8729 - val_acc: 0.7941\n",
            "Epoch 107/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 2.2156e-06 - acc: 1.0000 - val_loss: 1.8776 - val_acc: 0.7964\n",
            "Epoch 108/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 1.8554e-06 - acc: 1.0000 - val_loss: 1.8842 - val_acc: 0.7964\n",
            "Epoch 109/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 1.9467e-06 - acc: 1.0000 - val_loss: 1.8887 - val_acc: 0.7964\n",
            "Epoch 110/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 2.4466e-06 - acc: 1.0000 - val_loss: 1.8957 - val_acc: 0.7941\n",
            "Epoch 111/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 2.0703e-06 - acc: 1.0000 - val_loss: 1.9021 - val_acc: 0.7941\n",
            "Epoch 112/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 2.6318e-06 - acc: 1.0000 - val_loss: 1.9090 - val_acc: 0.7986\n",
            "Epoch 113/150\n",
            "49/49 [==============================] - 19s 393ms/step - loss: 2.3121e-06 - acc: 1.0000 - val_loss: 1.9170 - val_acc: 0.7986\n",
            "Epoch 114/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 1.3415e-06 - acc: 1.0000 - val_loss: 1.9237 - val_acc: 0.7986\n",
            "Epoch 115/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 1.5139e-06 - acc: 1.0000 - val_loss: 1.9267 - val_acc: 0.7964\n",
            "Epoch 116/150\n",
            "49/49 [==============================] - 20s 412ms/step - loss: 2.2075e-06 - acc: 1.0000 - val_loss: 1.9331 - val_acc: 0.7964\n",
            "Epoch 117/150\n",
            "49/49 [==============================] - 19s 397ms/step - loss: 3.3506e-06 - acc: 1.0000 - val_loss: 1.9393 - val_acc: 0.7986\n",
            "Epoch 118/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 2.7896e-06 - acc: 1.0000 - val_loss: 1.9474 - val_acc: 0.8009\n",
            "Epoch 119/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 2.8003e-06 - acc: 1.0000 - val_loss: 1.9565 - val_acc: 0.7964\n",
            "Epoch 120/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 1.3322e-06 - acc: 1.0000 - val_loss: 1.9616 - val_acc: 0.7986\n",
            "Epoch 121/150\n",
            "49/49 [==============================] - 20s 397ms/step - loss: 1.7332e-06 - acc: 1.0000 - val_loss: 1.9655 - val_acc: 0.8009\n",
            "Epoch 122/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 1.2566e-06 - acc: 1.0000 - val_loss: 1.9692 - val_acc: 0.7986\n",
            "Epoch 123/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 1.5288e-06 - acc: 1.0000 - val_loss: 1.9719 - val_acc: 0.7986\n",
            "Epoch 124/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 1.3256e-06 - acc: 1.0000 - val_loss: 1.9776 - val_acc: 0.7986\n",
            "Epoch 125/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 4.3226e-06 - acc: 1.0000 - val_loss: 1.9868 - val_acc: 0.7964\n",
            "Epoch 126/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 1.6838e-06 - acc: 1.0000 - val_loss: 1.9968 - val_acc: 0.7964\n",
            "Epoch 127/150\n",
            "49/49 [==============================] - 20s 415ms/step - loss: 1.2263e-06 - acc: 1.0000 - val_loss: 2.0052 - val_acc: 0.7964\n",
            "Epoch 128/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 1.4593e-06 - acc: 1.0000 - val_loss: 2.0177 - val_acc: 0.7964\n",
            "Epoch 129/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 2.3696e-06 - acc: 1.0000 - val_loss: 2.0253 - val_acc: 0.7986\n",
            "Epoch 130/150\n",
            "49/49 [==============================] - 20s 394ms/step - loss: 1.2945e-06 - acc: 1.0000 - val_loss: 2.0297 - val_acc: 0.8009\n",
            "Epoch 131/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 2.7136e-06 - acc: 1.0000 - val_loss: 2.0464 - val_acc: 0.8009\n",
            "Epoch 132/150\n",
            "49/49 [==============================] - 19s 398ms/step - loss: 1.0951e-06 - acc: 1.0000 - val_loss: 2.0467 - val_acc: 0.8009\n",
            "Epoch 133/150\n",
            "49/49 [==============================] - 19s 395ms/step - loss: 4.5897e-06 - acc: 1.0000 - val_loss: 2.0937 - val_acc: 0.8009\n",
            "Epoch 134/150\n",
            "49/49 [==============================] - 19s 394ms/step - loss: 3.2788e-06 - acc: 1.0000 - val_loss: 2.0754 - val_acc: 0.7964\n",
            "Epoch 135/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 1.2074e-06 - acc: 1.0000 - val_loss: 2.0655 - val_acc: 0.7964\n",
            "Epoch 136/150\n",
            "49/49 [==============================] - 19s 392ms/step - loss: 1.8626e-06 - acc: 1.0000 - val_loss: 2.0589 - val_acc: 0.7941\n",
            "Epoch 137/150\n",
            "49/49 [==============================] - 19s 389ms/step - loss: 1.2631e-06 - acc: 1.0000 - val_loss: 2.0611 - val_acc: 0.7941\n",
            "Epoch 138/150\n",
            "49/49 [==============================] - 20s 406ms/step - loss: 2.8770e-05 - acc: 1.0000 - val_loss: 2.1080 - val_acc: 0.7919\n",
            "Epoch 139/150\n",
            "49/49 [==============================] - 19s 389ms/step - loss: 5.7913e-06 - acc: 1.0000 - val_loss: 2.2037 - val_acc: 0.7873\n",
            "Epoch 140/150\n",
            "49/49 [==============================] - 19s 388ms/step - loss: 7.5631e-06 - acc: 1.0000 - val_loss: 2.1089 - val_acc: 0.7964\n",
            "Epoch 141/150\n",
            "49/49 [==============================] - 19s 391ms/step - loss: 1.9480e-06 - acc: 1.0000 - val_loss: 2.1167 - val_acc: 0.7964\n",
            "Epoch 142/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 1.4848e-06 - acc: 1.0000 - val_loss: 2.1255 - val_acc: 0.7964\n",
            "Epoch 143/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 1.3017e-06 - acc: 1.0000 - val_loss: 2.1320 - val_acc: 0.7964\n",
            "Epoch 144/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 1.2908e-06 - acc: 1.0000 - val_loss: 2.1410 - val_acc: 0.7964\n",
            "Epoch 145/150\n",
            "49/49 [==============================] - 20s 394ms/step - loss: 2.4782e-06 - acc: 1.0000 - val_loss: 2.1531 - val_acc: 0.7986\n",
            "Epoch 146/150\n",
            "49/49 [==============================] - 20s 395ms/step - loss: 1.1526e-06 - acc: 1.0000 - val_loss: 2.1665 - val_acc: 0.7986\n",
            "Epoch 147/150\n",
            "49/49 [==============================] - 20s 397ms/step - loss: 2.0815e-06 - acc: 1.0000 - val_loss: 2.1773 - val_acc: 0.7986\n",
            "Epoch 148/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 3.9680e-07 - acc: 1.0000 - val_loss: 2.1846 - val_acc: 0.8009\n",
            "Epoch 149/150\n",
            "49/49 [==============================] - 20s 413ms/step - loss: 7.2859e-07 - acc: 1.0000 - val_loss: 2.1932 - val_acc: 0.8009\n",
            "Epoch 150/150\n",
            "49/49 [==============================] - 20s 396ms/step - loss: 1.0919e-06 - acc: 1.0000 - val_loss: 2.1912 - val_acc: 0.8032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/model_moduk 6.h5')"
      ],
      "metadata": {
        "id": "aWV00BU75WcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAhxx5nqyBPW",
        "outputId": "4f7a345d-631c-4983-f7f1-75ff27efda27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict([x_val,x_val])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4adkIyCkMlHp",
        "outputId": "f47e4a18-e269-4b5c-d4d1-4d46c4459444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 7s 152ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array(x_test[0])\n",
        "\n",
        "model.predict([c,c])[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UMbX3mfdAZTP",
        "outputId": "4ca0e27a-4661-4e6f-9012-06d1a1eba43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-35b11b3383b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/zero_padding2d/Pad' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 985, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 787, in inner\n      self.run()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-48-2ab03d751c09>\", line 1, in <module>\n      model.predict([x_test[0], x_test[0]])\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 2033, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1845, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1834, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1823, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1791, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/layers/reshaping/zero_padding2d.py\", line 143, in call\n      return backend.spatial_2d_padding(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/backend.py\", line 3770, in spatial_2d_padding\n      return tf.compat.v1.pad(x, pattern)\nNode: 'model/zero_padding2d/Pad'\nThe first dimension of paddings must be the rank of inputs[4,2] [32,128,3]\n\t [[{{node model/zero_padding2d/Pad}}]] [Op:__inference_predict_function_111819]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {'CNN'   :   r'G:\\UMM\\Semester 7\\ML\\Modul 6\\aplikasi-web-deteksi-covid19\\Aplikasi Klasifikasi Covid 19\\static\\MLModule\\model_moduk cnn 6.h5',\n",
        "                  'Transferlearning'     :   r'G:\\UMM\\Semester 7\\ML\\Modul 6\\aplikasi-web-deteksi-covid19\\Aplikasi Klasifikasi Covid 19\\static\\MLModule\\model_moduk 6.h5',}\n",
        "    "
      ],
      "metadata": {
        "id": "30jKW21CCmpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict['CNN']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "hHsRltigCoGg",
        "outputId": "3771d0f4-c442-4f58-cecb-282df5b40038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'G:\\\\UMM\\\\Semester 7\\\\ML\\\\Modul 6\\\\aplikasi-web-deteksi-covid19\\\\Aplikasi Klasifikasi Covid 19\\\\static\\\\MLModule\\\\model_moduk cnn 6.h5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "for i in pred:\n",
        "  if i[0]>i[1]:\n",
        "    labels.append(0)\n",
        "  else:\n",
        "    labels.append(1)"
      ],
      "metadata": {
        "id": "_BpsponzM8QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_val,labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AX4QMVLNEX3",
        "outputId": "1f59cfe7-8d1a-462d-9288-44bbc7d3780e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.80       221\n",
            "           1       0.81      0.80      0.80       221\n",
            "\n",
            "    accuracy                           0.80       442\n",
            "   macro avg       0.80      0.80      0.80       442\n",
            "weighted avg       0.80      0.80      0.80       442\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
        "confusionM = confusion_matrix(y_val, labels)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusionM, display_labels = [False, True])\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "WufmZqiuNGCq",
        "outputId": "27696798-1615-432c-9e81-0a6471eaf595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss plot\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 130), H1.history[\"loss\"][20:], label=\"loss\")\n",
        "plt.plot(np.arange(0, 130), H1.history[\"val_loss\"][20:], label=\"val_loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "VzczY6HsNLS1",
        "outputId": "3ef1d222-2eac-4296-ad16-0ee13f8c27e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vl = H1.history[\"val_loss\"].copy()"
      ],
      "metadata": {
        "id": "eXF8xZUCNiGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vl.remove(H1.history[\"val_loss\"][16])"
      ],
      "metadata": {
        "id": "GNvirVHEN06G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vl.remove(H1.history[\"val_loss\"][17])"
      ],
      "metadata": {
        "id": "ggh8Mw89ORkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = H1.history[\"loss\"].copy()"
      ],
      "metadata": {
        "id": "kImv61bhPpJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l.remove(H1.history[\"loss\"][16])\n",
        "l.remove(H1.history[\"loss\"][17])"
      ],
      "metadata": {
        "id": "NoaMA39GPx4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te88uJeyQCaL",
        "outputId": "78123f64-10a1-4e1d-d303-237b7e1dbfa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzZpcnlDQEJr",
        "outputId": "955f5185-a11b-4af1-89ad-abd97a6dcb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss plot\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 112), l, label=\"loss\")\n",
        "plt.plot(np.arange(0, 112), vl, label=\"val_loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "97UAlBgAQF9l",
        "outputId": "c7dbdfcf-5758-42ac-dfb1-e5a4ae10b004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(3106,49152)"
      ],
      "metadata": {
        "id": "eBk-7yzKs_qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifNgTklothyZ",
        "outputId": "281e8b1d-2c0b-4ac5-ab0e-d0b2e346805b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3106, 49152)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel = \"rbf\", C = 1.0, gamma = 0.1)\n",
        "clf_svm = svm.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "lYiRJ5siQLVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training accuracy :\", clf_svm.score(x_train, y_train))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1WJUpxSw0CL",
        "outputId": "16d215c0-ba7e-406b-e894-d90e20251b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training accuracy : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbIhgZe5yowa",
        "outputId": "7db6cf9a-3dee-41d8-af2a-570e299d9625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(890, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test.reshape(890,49152)"
      ],
      "metadata": {
        "id": "7Bi26vgr2-fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"testing accuracy :\", clf_svm.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbrMMmww3J0o",
        "outputId": "62f1001f-d3f5-4378-c58a-9f7644d73c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing accuracy : 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qpfftgc6f3y"
      },
      "outputs": [],
      "source": [
        "# Gather train data\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for r,d,f in os.walk(trainDir):\n",
        "  for file in f:\n",
        "    if \".png\" in file:\n",
        "      image_path = os.path.join(r,file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.resize(image, (128,128))\n",
        "      x_train.append(image)\n",
        "      label = image_path.split(os.path.sep)[-2]\n",
        "      y_train.append(label)\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9-7RJRY6f3-"
      },
      "outputs": [],
      "source": [
        "# Gather validation data\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "for r,d,f in os.walk(valDir):\n",
        "  for file in f:\n",
        "    if \".png\" in file:\n",
        "      image_path = os.path.join(r,file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.resize(image, (128,128))\n",
        "      x_val.append(image)\n",
        "      label = image_path.split(os.path.sep)[-2]\n",
        "      y_val.append(label)\n",
        "\n",
        "x_val = np.array(x_val)\n",
        "y_val = np.array(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gather validation data\n",
        "\n",
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "for r,d,f in os.walk(testDir):\n",
        "  for file in f:\n",
        "    if \".png\" in file:\n",
        "      image_path = os.path.join(r,file)\n",
        "      image = cv2.imread(image_path)\n",
        "      image = cv2.resize(image, (128,128))\n",
        "      x_test.append(image)\n",
        "      label = image_path.split(os.path.sep)[-2]\n",
        "      y_test.append(label)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "CP4-Qj3T6f3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab5d8ee-3afb-4049-927b-13ca00bb1443",
        "id": "eZfFjkju6f3_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data= (3106, 128, 128, 3)\n",
            "Train Label= (3106,)\n",
            "Validation Data= (442, 128, 128, 3)\n",
            "Validation Label= (442,)\n",
            "Test Data= (890, 128, 128, 3)\n",
            "Test Label= (890,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Data=\", x_train.shape)\n",
        "print(\"Train Label=\", y_train.shape)\n",
        "print(\"Validation Data=\", x_val.shape)\n",
        "print(\"Validation Label=\", y_val.shape)\n",
        "print(\"Test Data=\", x_test.shape)\n",
        "print(\"Test Label=\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoder implementation in each train & test label\n",
        "lb = LabelEncoder()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_val = lb.fit_transform(y_val)\n",
        "y_test = lb.fit_transform(y_test)"
      ],
      "metadata": {
        "id": "e8Z9ILrY6f3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY4vZvPQTbPQ"
      },
      "outputs": [],
      "source": [
        "# normalize the scale in every images using ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implement ImageDataGenerator in train, test data, & each label\n",
        "train_iterator = datagen.flow(x_train, y_train, batch_size=64)\n",
        "val_iterator = datagen.flow(x_val, y_val, batch_size=64)\n",
        "print('Batches train=%d, validation=%d' % (len(train_iterator), len(val_iterator)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GTGepg33MSx",
        "outputId": "d3f09a50-e0b5-4798-aa33-836571ec9c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches train=49, validation=7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Dropout"
      ],
      "metadata": {
        "id": "LELFmGx44zxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4dUZJUZ6CcL",
        "outputId": "17d6546c-398d-4518-96f6-dd83bc420309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 128, 128, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128, 128, 32)      0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32, 32, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               4194432   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,297,889\n",
            "Trainable params: 4,297,441\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_2= Sequential()\n",
        "model_2.add(InputLayer(input_shape=[128,128,3]))\n",
        "\n",
        "model_2.add(Conv2D(32,3,padding='same',activation='relu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(MaxPooling2D(padding='same'))\n",
        "\n",
        "model_2.add(Conv2D(64,3,padding='same',activation='relu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(MaxPooling2D(padding='same'))\n",
        "\n",
        "model_2.add(Conv2D(128,3,padding='same',activation='relu'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(MaxPooling2D(padding='same'))\n",
        "\n",
        "model_2.add(Flatten())\n",
        "model_2.add(Dense(128, activation='relu'))\n",
        "model_2.add(Dense(64, activation='relu'))\n",
        "model_2.add(Dense(16, activation='relu'))\n",
        "model_2.add(Dense(1, activation='sigmoid'))\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qzV7lAsL3pRC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "54f8d9bb-bf90-4a31-a15d-4302e92001a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-da26f328e9d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz2SzIsK6oom",
        "outputId": "576b24a6-5720-4b24-b3b7-bbcdce2a6d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "49/49 [==============================] - 6s 93ms/step - loss: 1.1006 - accuracy: 0.5724 - val_loss: 6.5851 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.6163 - accuracy: 0.6648 - val_loss: 9.5681 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.5466 - accuracy: 0.7196 - val_loss: 7.9280 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.5176 - accuracy: 0.7263 - val_loss: 2.2719 - val_accuracy: 0.5294\n",
            "Epoch 5/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.4485 - accuracy: 0.7830 - val_loss: 0.7461 - val_accuracy: 0.5158\n",
            "Epoch 6/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.4226 - accuracy: 0.7978 - val_loss: 0.8388 - val_accuracy: 0.5475\n",
            "Epoch 7/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.3665 - accuracy: 0.8390 - val_loss: 1.0035 - val_accuracy: 0.5452\n",
            "Epoch 8/100\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.3423 - accuracy: 0.8461 - val_loss: 0.9540 - val_accuracy: 0.5724\n",
            "Epoch 9/100\n",
            "49/49 [==============================] - 4s 76ms/step - loss: 0.2738 - accuracy: 0.8838 - val_loss: 0.8778 - val_accuracy: 0.5860\n",
            "Epoch 10/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.2496 - accuracy: 0.8944 - val_loss: 0.8263 - val_accuracy: 0.6561\n",
            "Epoch 11/100\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.1529 - accuracy: 0.9398 - val_loss: 1.0068 - val_accuracy: 0.6425\n",
            "Epoch 12/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.1308 - accuracy: 0.9511 - val_loss: 1.0168 - val_accuracy: 0.6335\n",
            "Epoch 13/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0943 - accuracy: 0.9697 - val_loss: 1.0484 - val_accuracy: 0.6425\n",
            "Epoch 14/100\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.0793 - accuracy: 0.9701 - val_loss: 1.1215 - val_accuracy: 0.6561\n",
            "Epoch 15/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0555 - accuracy: 0.9813 - val_loss: 1.3098 - val_accuracy: 0.6312\n",
            "Epoch 16/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0933 - accuracy: 0.9665 - val_loss: 1.0431 - val_accuracy: 0.6697\n",
            "Epoch 17/100\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.0724 - accuracy: 0.9739 - val_loss: 1.0705 - val_accuracy: 0.6516\n",
            "Epoch 18/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 1.0908 - val_accuracy: 0.6357\n",
            "Epoch 19/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 1.1370 - val_accuracy: 0.6516\n",
            "Epoch 20/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0607 - accuracy: 0.9807 - val_loss: 1.5722 - val_accuracy: 0.6471\n",
            "Epoch 21/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 2.0893 - val_accuracy: 0.6561\n",
            "Epoch 22/100\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0109 - accuracy: 0.9981 - val_loss: 2.1624 - val_accuracy: 0.6425\n",
            "Epoch 23/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 1.6125 - val_accuracy: 0.6787\n",
            "Epoch 24/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 2.0954 - val_accuracy: 0.6719\n",
            "Epoch 25/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0229 - accuracy: 0.9913 - val_loss: 2.4997 - val_accuracy: 0.6131\n",
            "Epoch 26/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0145 - accuracy: 0.9968 - val_loss: 2.3358 - val_accuracy: 0.6403\n",
            "Epoch 27/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 1.9492 - val_accuracy: 0.6538\n",
            "Epoch 28/100\n",
            "49/49 [==============================] - 4s 73ms/step - loss: 0.0181 - accuracy: 0.9939 - val_loss: 1.9039 - val_accuracy: 0.6674\n",
            "Epoch 29/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0253 - accuracy: 0.9932 - val_loss: 1.6741 - val_accuracy: 0.6652\n",
            "Epoch 30/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 2.5203 - val_accuracy: 0.6290\n",
            "Epoch 31/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0139 - accuracy: 0.9955 - val_loss: 2.3990 - val_accuracy: 0.6267\n",
            "Epoch 32/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0106 - accuracy: 0.9971 - val_loss: 1.7144 - val_accuracy: 0.6425\n",
            "Epoch 33/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0064 - accuracy: 0.9981 - val_loss: 2.2729 - val_accuracy: 0.6652\n",
            "Epoch 34/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 2.4137 - val_accuracy: 0.6403\n",
            "Epoch 35/100\n",
            "49/49 [==============================] - 4s 76ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 3.2723 - val_accuracy: 0.6290\n",
            "Epoch 36/100\n",
            "49/49 [==============================] - 4s 71ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 2.2760 - val_accuracy: 0.6742\n",
            "Epoch 37/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 1.9498 - val_accuracy: 0.6538\n",
            "Epoch 38/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0476 - accuracy: 0.9829 - val_loss: 1.6359 - val_accuracy: 0.6448\n",
            "Epoch 39/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0752 - accuracy: 0.9739 - val_loss: 1.6802 - val_accuracy: 0.6244\n",
            "Epoch 40/100\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.0725 - accuracy: 0.9730 - val_loss: 2.8961 - val_accuracy: 0.6335\n",
            "Epoch 41/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0444 - accuracy: 0.9865 - val_loss: 1.3032 - val_accuracy: 0.6290\n",
            "Epoch 42/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0345 - accuracy: 0.9865 - val_loss: 1.9555 - val_accuracy: 0.6674\n",
            "Epoch 43/100\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0228 - accuracy: 0.9910 - val_loss: 1.7374 - val_accuracy: 0.6403\n",
            "Epoch 44/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 1.5025 - val_accuracy: 0.6267\n",
            "Epoch 45/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 1.7776 - val_accuracy: 0.6765\n",
            "Epoch 46/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 2.4604 - val_accuracy: 0.6471\n",
            "Epoch 47/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0071 - accuracy: 0.9971 - val_loss: 2.9342 - val_accuracy: 0.6380\n",
            "Epoch 48/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0272 - accuracy: 0.9903 - val_loss: 1.6493 - val_accuracy: 0.6154\n",
            "Epoch 49/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 2.4300 - val_accuracy: 0.6516\n",
            "Epoch 50/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0214 - accuracy: 0.9910 - val_loss: 1.5810 - val_accuracy: 0.6290\n",
            "Epoch 51/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 2.8420 - val_accuracy: 0.6561\n",
            "Epoch 52/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0146 - accuracy: 0.9948 - val_loss: 2.1855 - val_accuracy: 0.6538\n",
            "Epoch 53/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 2.0740 - val_accuracy: 0.6086\n",
            "Epoch 54/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 2.3913 - val_accuracy: 0.6606\n",
            "Epoch 55/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0226 - accuracy: 0.9948 - val_loss: 2.4397 - val_accuracy: 0.6357\n",
            "Epoch 56/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 2.8830 - val_accuracy: 0.6357\n",
            "Epoch 57/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 2.1494 - val_accuracy: 0.6471\n",
            "Epoch 58/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0111 - accuracy: 0.9961 - val_loss: 1.8370 - val_accuracy: 0.6425\n",
            "Epoch 59/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 2.0541 - val_accuracy: 0.6629\n",
            "Epoch 60/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0037 - accuracy: 0.9984 - val_loss: 2.0745 - val_accuracy: 0.6652\n",
            "Epoch 61/100\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 2.7145 - val_accuracy: 0.6606\n",
            "Epoch 62/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0036 - accuracy: 0.9984 - val_loss: 3.3260 - val_accuracy: 0.6538\n",
            "Epoch 63/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 2.6872 - val_accuracy: 0.6606\n",
            "Epoch 64/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 1.9337 - val_accuracy: 0.6561\n",
            "Epoch 65/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 2.8040 - val_accuracy: 0.6561\n",
            "Epoch 66/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 2.9470 - val_accuracy: 0.6448\n",
            "Epoch 67/100\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 3.6351 - val_accuracy: 0.6652\n",
            "Epoch 68/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 3.5122 - val_accuracy: 0.6425\n",
            "Epoch 69/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 4.1124 - val_accuracy: 0.6335\n",
            "Epoch 70/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8544 - val_accuracy: 0.6538\n",
            "Epoch 71/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 3.5623 - val_accuracy: 0.6425\n",
            "Epoch 72/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0336 - accuracy: 0.9913 - val_loss: 2.6221 - val_accuracy: 0.6176\n",
            "Epoch 73/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0369 - accuracy: 0.9881 - val_loss: 2.1636 - val_accuracy: 0.6471\n",
            "Epoch 74/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0232 - accuracy: 0.9910 - val_loss: 3.6415 - val_accuracy: 0.6290\n",
            "Epoch 75/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 1.7066 - val_accuracy: 0.6086\n",
            "Epoch 76/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0365 - accuracy: 0.9887 - val_loss: 2.5066 - val_accuracy: 0.6290\n",
            "Epoch 77/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0171 - accuracy: 0.9932 - val_loss: 1.5519 - val_accuracy: 0.5995\n",
            "Epoch 78/100\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 1.4110 - val_accuracy: 0.6471\n",
            "Epoch 79/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 2.1841 - val_accuracy: 0.6516\n",
            "Epoch 80/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 2.6635 - val_accuracy: 0.6765\n",
            "Epoch 81/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 2.0466 - val_accuracy: 0.6199\n",
            "Epoch 82/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0104 - accuracy: 0.9971 - val_loss: 1.9870 - val_accuracy: 0.6357\n",
            "Epoch 83/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0074 - accuracy: 0.9981 - val_loss: 2.7240 - val_accuracy: 0.6652\n",
            "Epoch 84/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 2.7759 - val_accuracy: 0.6380\n",
            "Epoch 85/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 2.2971 - val_accuracy: 0.6538\n",
            "Epoch 86/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0061 - accuracy: 0.9968 - val_loss: 3.4067 - val_accuracy: 0.6290\n",
            "Epoch 87/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0118 - accuracy: 0.9968 - val_loss: 1.9619 - val_accuracy: 0.6086\n",
            "Epoch 88/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 2.4919 - val_accuracy: 0.6584\n",
            "Epoch 89/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 3.5918 - val_accuracy: 0.6403\n",
            "Epoch 90/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.8257 - val_accuracy: 0.6290\n",
            "Epoch 91/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0151 - accuracy: 0.9952 - val_loss: 2.9459 - val_accuracy: 0.6425\n",
            "Epoch 92/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0271 - accuracy: 0.9900 - val_loss: 2.6772 - val_accuracy: 0.5928\n",
            "Epoch 93/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0156 - accuracy: 0.9920 - val_loss: 2.0441 - val_accuracy: 0.6584\n",
            "Epoch 94/100\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 1.8587 - val_accuracy: 0.6312\n",
            "Epoch 95/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0068 - accuracy: 0.9965 - val_loss: 2.8336 - val_accuracy: 0.6493\n",
            "Epoch 96/100\n",
            "49/49 [==============================] - 3s 70ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 2.5825 - val_accuracy: 0.6584\n",
            "Epoch 97/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 1.9924 - val_accuracy: 0.6629\n",
            "Epoch 98/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0054 - accuracy: 0.9984 - val_loss: 2.3442 - val_accuracy: 0.6425\n",
            "Epoch 99/100\n",
            "49/49 [==============================] - 4s 74ms/step - loss: 0.0046 - accuracy: 0.9981 - val_loss: 3.5940 - val_accuracy: 0.6380\n",
            "Epoch 100/100\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 3.5131 - val_accuracy: 0.6697\n"
          ]
        }
      ],
      "source": [
        "# training & saving history of every epoch on model 2\n",
        "H2 = model_2.fit(train_iterator, epochs=100, validation_data=val_iterator)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save('/content/drive/MyDrive/model_moduk cnn 6.h5')"
      ],
      "metadata": {
        "id": "WPQWyFUb5YYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p2sqMOH-8I3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}